{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b7c0831",
   "metadata": {},
   "outputs": [],
   "source": [
    "import parse_genet\n",
    "import os\n",
    "import sys\n",
    "import getopt\n",
    "\n",
    "import vi\n",
    "\n",
    "import importlib\n",
    "\n",
    "import simulate\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import pyro.distributions as dist\n",
    "\n",
    "import scipy.stats\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a231ed4",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() missing 8 required positional arguments: 'beta_mrg', 'n', 'p', 'ld_blk', 'ld_blk_chol', 'blk_size', 'annotations', and 'torch_type'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-c8aa864f0924>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mvi_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: __init__() missing 8 required positional arguments: 'beta_mrg', 'n', 'p', 'ld_blk', 'ld_blk_chol', 'blk_size', 'annotations', and 'torch_type'"
     ]
    }
   ],
   "source": [
    "vi_test = vi.Data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4e191979",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... parse reference file: /gpfs/commons/groups/knowles_lab/data/ADSP_reguloML/LD_PRScs/ldblk_ukbb_eur/snpinfo_ukbb_hm3 ...\n",
      "... parse sumstats file: test_data/wightman_chr22.tsv ...\n",
      "... 14014 common SNPs in the reference, sumstats, and validation set ...\n",
      "... parse reference LD on chromosome 22 ...\n"
     ]
    }
   ],
   "source": [
    "chrom=22\n",
    "param_dict = {\n",
    "    'ref_dir' : '/gpfs/commons/groups/knowles_lab/data/ADSP_reguloML/LD_PRScs/ldblk_ukbb_eur', ## add my path\n",
    "    'bim_prefix' : \"test_data/ADSP_qc_chr22\", \n",
    "    'sst_file' : \"test_data/wightman_chr22.tsv\", \n",
    "    'n_gwas' : 200000, \n",
    "    'out_dir' : \"test_data\",\n",
    "    \"seed\" : 42, \n",
    "    \"beta_std\" : \"False\", \n",
    "    \"n_iter\" : 1000\n",
    "}\n",
    "\n",
    "ref_df = parse_genet.parse_ref(param_dict['ref_dir'] + '/snpinfo_ukbb_hm3')\n",
    "\n",
    "\n",
    "ref_df = ref_df[ref_df.CHR == chrom]\n",
    "vld_df = parse_genet.parse_bim(param_dict['bim_prefix'] + \".bim\")\n",
    "vld_df = vld_df[vld_df.CHR == chrom]\n",
    "sst_dict = parse_genet.parse_sumstats(ref_df, vld_df, param_dict['sst_file'], param_dict['n_gwas']) ## take the interception SNP of sumstat, ref_ld, validate df\n",
    "ld_blk, ld_blk_sym, blk_size = parse_genet.parse_ldblk(param_dict['ref_dir'], sst_dict, chrom)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6e806563",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n",
      "24\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[226,\n",
       " 264,\n",
       " 618,\n",
       " 711,\n",
       " 421,\n",
       " 416,\n",
       " 853,\n",
       " 756,\n",
       " 657,\n",
       " 600,\n",
       " 394,\n",
       " 971,\n",
       " 530,\n",
       " 931,\n",
       " 610,\n",
       " 386,\n",
       " 518,\n",
       " 417,\n",
       " 717,\n",
       " 659,\n",
       " 493,\n",
       " 761,\n",
       " 617,\n",
       " 488]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(ld_blk)) ## 4 blocks\n",
    "print(len(ld_blk_sym)) ## same 4 blocks\n",
    "blk_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "193b0d72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        , -0.594883  , -0.854701  , ..., -0.029778  ,\n",
       "        -0.0611675 , -0.0623354 ],\n",
       "       [-0.594883  ,  1.        ,  0.432201  , ...,  0.0220252 ,\n",
       "         0.0248158 ,  0.028129  ],\n",
       "       [-0.854701  ,  0.432201  ,  1.        , ..., -0.00325899,\n",
       "         0.0440021 ,  0.0483626 ],\n",
       "       ...,\n",
       "       [-0.029778  ,  0.0220252 , -0.00325899, ...,  1.        ,\n",
       "         0.88211   ,  0.876589  ],\n",
       "       [-0.0611675 ,  0.0248158 ,  0.0440021 , ...,  0.88211   ,\n",
       "         1.        ,  0.993641  ],\n",
       "       [-0.0623354 ,  0.028129  ,  0.0483626 , ...,  0.876589  ,\n",
       "         0.993641  ,  1.        ]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ld_blk[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ca85bc00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array_equal(ld_blk_sym[0] , ld_blk[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "819db06b",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_blk = len(hdf_chr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d5d95009",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/commons/home/tlin/.conda/envs/polyfun/lib/python3.6/site-packages/ipykernel_launcher.py:4: DeprecationWarning: scipy.array is deprecated and will be removed in SciPy 2.0.0, use numpy.array instead\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "import scipy as sp\n",
    "import h5py\n",
    "hdf_chr = h5py.File(param_dict['ref_dir'] + '/ldblk_ukbb_chr' + str(chrom) + '.hdf5', 'r')\n",
    "ld_blk = [sp.array(hdf_chr['blk_'+str(blk)]['ldblk']) for blk in range(1,n_blk+1)]\n",
    "\n",
    "snp_blk = []\n",
    "for blk in range(1,n_blk+1):\n",
    "    snp_blk.append([bb.decode(\"UTF-8\") for bb in list(hdf_chr['blk_'+str(blk)]['snplist'])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "41a06166",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(snp_blk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e1872845",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rs17210001\n"
     ]
    }
   ],
   "source": [
    "### the way to read snp\n",
    "for i in list(hdf_chr['blk_4']['snplist']):\n",
    "    print(i.decode(\"UTF-8\"))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0fb2b271",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "226\n",
      "264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/commons/home/tlin/.conda/envs/polyfun/lib/python3.6/site-packages/ipykernel_launcher.py:15: DeprecationWarning: scipy.ix_ is deprecated and will be removed in SciPy 2.0.0, use numpy.ix_ instead\n",
      "  from ipykernel import kernelapp as app\n",
      "/gpfs/commons/home/tlin/.conda/envs/polyfun/lib/python3.6/site-packages/ipykernel_launcher.py:15: DeprecationWarning: scipy.outer is deprecated and will be removed in SciPy 2.0.0, use numpy.outer instead\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "618\n",
      "711\n",
      "421\n",
      "416\n",
      "853\n",
      "756\n",
      "657\n",
      "600\n",
      "394\n",
      "971\n",
      "530\n",
      "931\n",
      "610\n",
      "386\n",
      "518\n",
      "417\n",
      "717\n",
      "659\n",
      "493\n",
      "761\n",
      "617\n",
      "488\n"
     ]
    }
   ],
   "source": [
    "    blk_size = []\n",
    "    ld_blk_sym = []\n",
    "    ld_blk_filt = []\n",
    "    mm = 0\n",
    "    for blk in range(n_blk):\n",
    "        idx = [ii for (ii, snp) in enumerate(snp_blk[blk]) if snp in sst_dict['SNP'].to_numpy() ]\n",
    "        print(len(idx))\n",
    "        if len(idx) == 0: \n",
    "            continue\n",
    "        \n",
    "        blk_size.append(len(idx))\n",
    "        \n",
    "        idx_blk = np.arange(mm,mm+len(idx))\n",
    "        flip = sst_dict['FLP'][idx_blk]\n",
    "        ld_blk_here = ld_blk[blk][sp.ix_(idx,idx)]*sp.outer(flip,flip)\n",
    "        ld_blk_filt.append(ld_blk_here)\n",
    "        \n",
    "        #_, s, v = linalg.svd(ld_blk_here)\n",
    "        #h = sp.dot(v.T, sp.dot(sp.diag(s), v)) # just weird way of getting transpose?! \n",
    "        #ld_blk_sym.append( (ld_blk_here+h)/2 )\n",
    "        \n",
    "        ld_blk_sym.append( (ld_blk_here+ld_blk_here.T)/2 )\n",
    "\n",
    "        mm += len(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a9a15131",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[226,\n",
       " 264,\n",
       " 618,\n",
       " 711,\n",
       " 421,\n",
       " 416,\n",
       " 853,\n",
       " 756,\n",
       " 657,\n",
       " 600,\n",
       " 394,\n",
       " 971,\n",
       " 530,\n",
       " 931,\n",
       " 610,\n",
       " 386,\n",
       " 518,\n",
       " 417,\n",
       " 717,\n",
       " 659,\n",
       " 493,\n",
       " 761,\n",
       " 617,\n",
       " 488]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blk_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d3b82cee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f9df007",
   "metadata": {},
   "source": [
    "## test_out simulate.py  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e7e89204",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... parse sumstats file: test_data/sumstats.txt ...\n",
      "... 1000 common SNPs in the reference, sumstats, and validation set ...\n",
      "... parse reference LD on chromosome 22 ...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'p' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-38ee34d4da7a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mbeta_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta_mrg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mannotations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msimulate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimulate_sumstats\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mld_blk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblk_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'n_gwas'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msst_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mannotations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnz\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'p' is not defined"
     ]
    }
   ],
   "source": [
    "ref_df = ref_df[ref_df.CHR == chrom]\n",
    "vld_df = parse_genet.parse_bim(param_dict['bim_prefix'] + \".bim\")\n",
    "vld_df = vld_df[vld_df.CHR == chrom]\n",
    "sst_dict = parse_genet.parse_sumstats(ref_df, vld_df, param_dict['sst_file'], param_dict['n_gwas']) ## take the interception SNP of sumstat, ref_ld, validate df\n",
    "ld_blk, ld_blk_sym, blk_size = parse_genet.parse_ldblk(param_dict['ref_dir'], sst_dict, chrom) ## ld_blk & ld_blk_sym are the equal here.\n",
    "\n",
    "\n",
    "#mcmc_gtb.mcmc(param_dict['a'], param_dict['b'], param_dict['phi'], sst_dict, param_dict['n_gwas'], ld_blk, blk_size, param_dict['n_iter'], param_dict['n_burnin'], param_dict['thin'], int(chrom), param_dict['out_dir'], param_dict['beta_std'], param_dict['seed'])\n",
    "\n",
    "beta_true, beta_mrg, annotations = simulate.simulate_sumstats(ld_blk, blk_size, param_dict['n_gwas'], p = len(sst_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7ab67256",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "2e99ad62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sst_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6d4abb1d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0.,  ..., 0., 0., 0.])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = len(sst_dict)\n",
    "nz = torch.rand(p) < 0.2\n",
    "beta_true = torch.where(nz, 0.1 * torch.randn(p), torch.zeros(p))\n",
    "beta_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "799439c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
       "        [ 1.0000,  0.0000,  1.0000,  ...,  1.0000,  0.0000,  0.0000],\n",
       "        [-0.3444,  0.8976,  0.0366,  ..., -0.7617,  0.5392, -0.6843]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotations = torch.stack([torch.ones(p),nz,torch.randn(p)])\n",
    "annotations ## for every snp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "63761fdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(annotations[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b41f0460",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225])\n",
      "tensor([[ 1.0000,  0.9992,  0.6384,  ...,  0.0088,  0.0059,  0.0076],\n",
      "        [ 0.9992,  1.0000,  0.6383,  ...,  0.0086,  0.0061,  0.0072],\n",
      "        [ 0.6384,  0.6383,  1.0000,  ..., -0.0063, -0.0045, -0.0012],\n",
      "        ...,\n",
      "        [ 0.0088,  0.0086, -0.0063,  ...,  1.0000,  0.3420,  0.3074],\n",
      "        [ 0.0059,  0.0061, -0.0045,  ...,  0.3420,  1.0000,  0.5585],\n",
      "        [ 0.0076,  0.0072, -0.0012,  ...,  0.3074,  0.5585,  1.0000]])\n"
     ]
    }
   ],
   "source": [
    "mm=0\n",
    "for kk in range(len(ld_blk)):\n",
    "    idx_blk = torch.arange(mm,mm+blk_size[kk])\n",
    "    ld_torch = torch.tensor(ld_blk[kk], dtype = torch.float)\n",
    "    print(idx_blk)\n",
    "    print(ld_torch)\n",
    "    L, V = torch.linalg.eigh(ld_torch)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3beb609a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-2.8701e-07, -2.5933e-07, -2.4489e-07, -1.9719e-07, -1.4229e-07,\n",
       "        -9.1758e-08, -6.8323e-08, -4.0874e-08, -2.9425e-08, -1.5823e-08,\n",
       "         1.0808e-09,  6.1763e-09,  2.8092e-08,  6.1921e-08,  8.2929e-08,\n",
       "         1.2159e-07,  1.5997e-07,  2.2286e-07,  2.4746e-07,  3.6694e-07,\n",
       "         7.9440e-07,  1.5274e-03,  1.6464e-03,  1.7237e-03,  1.7317e-03,\n",
       "         2.0195e-03,  2.1671e-03,  2.3259e-03,  2.6552e-03,  2.7704e-03,\n",
       "         3.1001e-03,  4.0371e-03,  4.2736e-03,  4.7468e-03,  5.0005e-03,\n",
       "         5.4366e-03,  5.7589e-03,  6.5098e-03,  7.2803e-03,  7.5573e-03,\n",
       "         7.8616e-03,  8.9578e-03,  9.3030e-03,  1.1276e-02,  1.1653e-02,\n",
       "         1.2443e-02,  1.3063e-02,  1.3592e-02,  1.4437e-02,  1.7321e-02,\n",
       "         1.7821e-02,  2.0109e-02,  2.1693e-02,  2.3077e-02,  2.4719e-02,\n",
       "         2.7001e-02,  3.5196e-02,  3.6366e-02,  3.9364e-02,  3.9530e-02,\n",
       "         4.2396e-02,  4.5874e-02,  5.1111e-02,  5.3921e-02,  5.6995e-02,\n",
       "         5.8743e-02,  6.2307e-02,  6.7301e-02,  7.3898e-02,  7.7166e-02,\n",
       "         8.3501e-02,  8.9109e-02,  9.3467e-02,  1.0344e-01,  1.1249e-01,\n",
       "         1.2057e-01,  1.2991e-01,  1.3788e-01,  1.4241e-01,  1.5653e-01,\n",
       "         1.6920e-01,  1.7860e-01,  1.8955e-01,  1.9145e-01,  2.0492e-01,\n",
       "         2.2392e-01,  2.3787e-01,  2.4594e-01,  2.5502e-01,  2.6072e-01,\n",
       "         2.6422e-01,  2.9176e-01,  3.1941e-01,  3.4134e-01,  3.6604e-01,\n",
       "         4.0651e-01,  4.1859e-01,  4.8126e-01,  5.4222e-01,  5.7494e-01,\n",
       "         6.3661e-01,  6.4635e-01,  7.1327e-01,  7.6256e-01,  8.2307e-01,\n",
       "         8.6917e-01,  9.0923e-01,  9.8009e-01,  9.8194e-01,  1.0901e+00,\n",
       "         1.1096e+00,  1.2146e+00,  1.3391e+00,  1.4264e+00,  1.4584e+00,\n",
       "         2.0311e+00,  2.2289e+00,  2.2871e+00,  2.4785e+00,  2.9592e+00,\n",
       "         3.1409e+00,  3.3031e+00,  3.9997e+00,  4.2668e+00,  4.3398e+00,\n",
       "         4.6066e+00,  5.3770e+00,  5.6377e+00,  6.4918e+00,  7.6062e+00,\n",
       "         7.8822e+00,  8.6802e+00,  9.6974e+00,  1.1700e+01,  1.2926e+01])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "baba30b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.       , -0.14631  ,  0.210427 , ..., -0.0103829, -0.0318179,\n",
       "         0.0256598],\n",
       "       [-0.14631  ,  1.       , -0.0522206, ..., -0.0409753, -0.0467828,\n",
       "        -0.0328089],\n",
       "       [ 0.210427 , -0.0522206,  1.       , ..., -0.0467965, -0.057888 ,\n",
       "         0.0332181],\n",
       "       ...,\n",
       "       [-0.0103829, -0.0409753, -0.0467965, ...,  1.       ,  0.967532 ,\n",
       "        -0.187081 ],\n",
       "       [-0.0318179, -0.0467828, -0.057888 , ...,  0.967532 ,  1.       ,\n",
       "        -0.214542 ],\n",
       "       [ 0.0256598, -0.0328089,  0.0332181, ..., -0.187081 , -0.214542 ,\n",
       "         1.       ]])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ld_blk[0] ## ld_torch= ld_blk[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a71260e9",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "size mismatch, got 255, 255x255,226",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-efad4af61aa0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mL\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mL\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0.\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mbeta_mrg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx_blk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mld_torch\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mbeta_true\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx_blk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msigma_over_sqrt_n\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mV\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblk_size\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0;31m#ld_torch @ beta_true[idx_blk],\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;31m# covariance_matrix = ld_torch * sigma_over_sqrt_n**2).rsample()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: size mismatch, got 255, 255x255,226"
     ]
    }
   ],
   "source": [
    "sigma_over_sqrt_n = 1. / torch.sqrt(torch.tensor(param_dict['n_gwas']))\n",
    "beta_mrg = torch.zeros(p)\n",
    "mm = 0\n",
    "for kk in range(len(ld_blk)):\n",
    "        idx_blk = torch.arange(mm,mm+blk_size[kk])\n",
    "        ld_torch = torch.tensor(ld_blk[kk], dtype = torch.float)\n",
    "        L, V = torch.linalg.eigh(ld_torch)\n",
    "        L[L < 0.] = 0.\n",
    "\n",
    "        beta_mrg[idx_blk] = ld_torch @ beta_true[idx_blk] + sigma_over_sqrt_n * (V @ torch.diag(L.sqrt())) @ torch.randn(blk_size[kk])\n",
    "        #ld_torch @ beta_true[idx_blk], \n",
    "        # covariance_matrix = ld_torch * sigma_over_sqrt_n**2).rsample()\n",
    "        mm += blk_size[kk]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "649426ea",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Looks like you want to use graphviz (https://graphviz.org/) to render your model. You need to install `graphviz` to be able to use this feature. It can be installed with `pip install graphviz`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m~/.conda/envs/polyfun/lib/python3.6/site-packages/pyro/infer/inspect.py\u001b[0m in \u001b[0;36mrender_graph\u001b[0;34m(graph_specification, render_distributions)\u001b[0m\n\u001b[1;32m    400\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 401\u001b[0;31m         \u001b[0;32mimport\u001b[0m \u001b[0mgraphviz\u001b[0m  \u001b[0;31m# noqa: F401\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    402\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'graphviz'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mImportError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-f44c4d3551b5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mpyro\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"obs\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNormal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlog_gdp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m \u001b[0mpyro\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msimple_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_args\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_cont_africa\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mruggedness\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_gdp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrender_distributions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.conda/envs/polyfun/lib/python3.6/site-packages/pyro/infer/inspect.py\u001b[0m in \u001b[0;36mrender_model\u001b[0;34m(model, model_args, model_kwargs, filename, render_distributions)\u001b[0m\n\u001b[1;32m    494\u001b[0m     \u001b[0mrelations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_model_relations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m     \u001b[0mgraph_spec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_graph_specification\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrelations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 496\u001b[0;31m     \u001b[0mgraph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrender_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph_spec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrender_distributions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrender_distributions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    497\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/polyfun/lib/python3.6/site-packages/pyro/infer/inspect.py\u001b[0m in \u001b[0;36mrender_graph\u001b[0;34m(graph_specification, render_distributions)\u001b[0m\n\u001b[1;32m    406\u001b[0m             \u001b[0;34m\"You need to install `graphviz` to be able to use this feature. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    407\u001b[0m             \u001b[0;34m\"It can be installed with `pip install graphviz`.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 408\u001b[0;31m         ) from e\n\u001b[0m\u001b[1;32m    409\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m     \u001b[0mplate_groups\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_specification\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"plate_groups\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: Looks like you want to use graphviz (https://graphviz.org/) to render your model. You need to install `graphviz` to be able to use this feature. It can be installed with `pip install graphviz`."
     ]
    }
   ],
   "source": [
    "#import pyro\n",
    "#import pyro.distributions as dist\n",
    "#import pyro.distributions.constraints as constraints\n",
    "import logging\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "DATA_URL = \"https://d2hg8soec8ck9v.cloudfront.net/datasets/rugged_data.csv\"\n",
    "data = pd.read_csv(DATA_URL, encoding=\"ISO-8859-1\")\n",
    "df = data[[\"cont_africa\", \"rugged\", \"rgdppc_2000\"]]\n",
    "\n",
    "df = df[np.isfinite(df.rgdppc_2000)]\n",
    "df[\"rgdppc_2000\"] = np.log(df[\"rgdppc_2000\"])\n",
    "\n",
    "train = torch.tensor(df.values, dtype=torch.float)\n",
    "is_cont_africa, ruggedness, log_gdp = train[:, 0], train[:, 1], train[:, 2]\n",
    "\n",
    "def simple_model(is_cont_africa, ruggedness, log_gdp=None):\n",
    "    a = pyro.param(\"a\", lambda: torch.randn(()))\n",
    "    b_a = pyro.param(\"bA\", lambda: torch.randn(()))\n",
    "    b_r = pyro.param(\"bR\", lambda: torch.randn(()))\n",
    "    b_ar = pyro.param(\"bAR\", lambda: torch.randn(()))\n",
    "    sigma = pyro.param(\"sigma\", lambda: torch.ones(()), constraint=constraints.positive)\n",
    "\n",
    "    mean = a + b_a * is_cont_africa + b_r * ruggedness + b_ar * is_cont_africa * ruggedness\n",
    "\n",
    "    with pyro.plate(\"data\", len(ruggedness)):\n",
    "        return pyro.sample(\"obs\", dist.Normal(mean, sigma), obs=log_gdp)\n",
    "\n",
    "pyro.render_model(simple_model, model_args=(is_cont_africa, ruggedness, log_gdp), render_distributions=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3631d290",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "render_model() got an unexpected keyword argument 'render_params'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-bc8f439199bc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpyro\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msimple_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_args\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_cont_africa\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mruggedness\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_gdp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrender_distributions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrender_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: render_model() got an unexpected keyword argument 'render_params'"
     ]
    }
   ],
   "source": [
    "pyro.render_model(simple_model, model_args=(is_cont_africa, ruggedness, log_gdp), render_distributions=True, render_params=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f47291",
   "metadata": {},
   "outputs": [],
   "source": [
    " def load_annotations_file(self, args, chr_num, use_ridge):\n",
    "        \n",
    "        #load annotations file for this chromosome\n",
    "        if use_ridge:\n",
    "            annot_filenames = get_file_name(args, 'annot', chr_num, allow_multiple=True)\n",
    "        else:\n",
    "            annot_filenames = [get_file_name(args, 'bins', chr_num)]\n",
    "        \n",
    "        #load annotation file(s)\n",
    "        df_annot_chr_list = []\n",
    "        for annot_filename in annot_filenames:\n",
    "            try:\n",
    "                df_annot_chr = pd.read_parquet(annot_filename)\n",
    "            except (ArrowIOError, ArrowInvalid):\n",
    "                df_annot_chr = pd.read_table(annot_filename)\n",
    "            df_annot_chr_list.append(df_annot_chr)\n",
    "        if len(df_annot_chr_list)==1:\n",
    "            df_annot_chr = df_annot_chr_list[0]\n",
    "        else:\n",
    "            for df in df_annot_chr_list[1:]:\n",
    "                for snp_col in SNP_COLUMNS:\n",
    "                    if (df.shape[0] != df_annot_chr_list[0].shape[0]) or (np.any(df[snp_col] != df_annot_chr_list[0][snp_col])):\n",
    "                        raise ValueError('Different annotation files of chromosome %d must be perfectly aligned'%(chr_num))\n",
    "                df.drop(columns=['CM'], inplace=True, errors='ignore')\n",
    "                df.drop(columns=SNP_COLUMNS, inplace=True, errors='raise')\n",
    "            df_annot_chr = pd.concat(df_annot_chr_list, axis=1)\n",
    "        \n",
    "        #make sure all required columns were found\n",
    "        df_annot_chr.drop(columns=['CM'], inplace=True, errors='ignore')\n",
    "        found_missing_col = False\n",
    "        for colname in SNP_COLUMNS:\n",
    "            if colname not in df_annot_chr.columns:\n",
    "                logging.error('%s has a missing column: %s'%(annot_filename, colname))\n",
    "                found_missing_col = True\n",
    "        if found_missing_col:\n",
    "            raise ValueError('Missing columns found in %s'%(annot_filename))\n",
    "            \n",
    "        #subset annotations if requested\n",
    "        if args.anno is not None:\n",
    "            anno_to_use = args.anno.split(',')\n",
    "            assert np.all(np.isin(anno_to_use, df_annot_chr.columns))\n",
    "            df_annot_chr = df_annot_chr[SNP_COLUMNS + anno_to_use]\n",
    "            \n",
    "        #if we have more annotations that ref-ld, it might mean that some annotations were removed, so remove them from here as well\n",
    "        if not np.all(np.isin(self.ref_ld_cnames, df_annot_chr.columns)):\n",
    "            missing_annot = [c for c in self.ref_ld_cnames if c not in df_annot_chr.columns]\n",
    "            raise ValueError('The following annotations have LD-scores but are not in any of the annotation files: %s'%(missing_annot))\n",
    "        if len(self.ref_ld_cnames) < len(df_annot_chr.columns) - len(SNP_COLUMNS):            \n",
    "            df_annot_chr = df_annot_chr[SNP_COLUMNS + self.ref_ld_cnames]\n",
    "\n",
    "        #make sure that we get the same columns as the ones in the LD-score files\n",
    "        if not np.all([c for c in df_annot_chr.columns if c not in SNP_COLUMNS ]== self.ref_ld_cnames):\n",
    "            raise ValueError('Annotation names in annotations file do not match the one in the LD-scores file')            \n",
    "\n",
    "        return df_annot_chr"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
